# HumanLessAI

## Overview
Just remember the following things, to get involved in this project: 
- **Manage Everything That Matters**
    - Convert all factors capable of influencing model behavior into readable & executable configurations. <!-- 모델 성능이나 행동에 영향을 줄 수 있는 모든 것들을 읽기 쉽고 실행 가능한 설정으로 만들어서 반드시 기록하라. // 사람의 기억력과 커뮤니케이션 능력을 신뢰하지 말아라. -->
    - e.g., dataset versioning, data preprocessing logic updates, adjustments in loss functions, learning rates, evaluation protocols, etc.
- **Collaborate Widely, Automate Wisely**
    - Amplify your efforts through collaboration, not only with humans, but also with AI. <!-- 혼자 일하기보다 열 사람이 함께 일하라. 그리고 그보다 더 많은 AI가 쉬지 않고 일을 할 수 있도록 만들어라. // 사람의 생산성을 지치지 않는 AI로 복제하라 -->
    - e.g., AI-driven research discussion, auto commenting workflow, AI-based consistency check on logic implementations, automatic cloud launching, automatic tutorial generation, etc.
- **Share and Inspire**
    - Make your small experiments known and find significance in even the minor discoveries. Inspire and be inspired by allowing more people to connect with your vision and imagination. <!-- 당신의 아주 사소한 실험도 공유하고, 당신의 작은 발견에도 의미를 부여하라. 더 많은 사람이 당신의 위대한 상상력에 공감하게 만들어라. // 공감을 얻지 못 하는 연구는 지속되기 어렵다 -->
    - e.g., technical blogs, seminars, paper publications, open discussions, participating in academic reviews, etc. 

## Key Features (TBU)

- **Dynamic Configuration Tracking**
- **AI Software Engineer**
- **Experimental Hub**

## Plans
1. Pre-training of BERT, RoBERTa, Longformer, GPT, and T5.
2. Fine-tuning of machine translation models with state-of-the-art LLMs.
3. 1M context length fine-tuning method.
4. GPT-based data augmentation.